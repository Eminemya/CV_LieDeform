
\section{Introduction}
\label{sec:introduction}

The changes in shapes of objects, often referred to as
\emph{deformations}, are widely observed in computer vision data.
In many problems, particularly object recognition based on appearance,
the performance can be greatly influenced by deformations. 
Whereas the past decades have seen tremendous efforts devoted to the
development of features and classifiers that are resilient to
variations of shapes and poses, the modeling of deformations has been
not been extensively explored. 
%
In this paper, we focus on modeling deformations, aiming to
develop a method that can decouple deformation from appearance of an
observed image. 

In past decades, a variety of approaches have been developed to
address the issue of deformations, for which we provide a brief review
in next section. Careful examination of previous shows that they are
limited in several aspects:
(1) While extensive research~\cite{ISO,LLE} has been performed on image
manifold modeling, this does not lead to effective modeling of deformations.
The problem here is that the differences between neighboring images
are due to the compound effects of deformations and other contributing
factors, and these approaches lack a mechanism to decouple the
effects.
(2) The methods for deformation-resilient
metrics~\cite{SC,IDM} aim to suppress the influence of deformation
on discriminative performance, which again does not offer an explicit
deformation model.
(3) Other work that explicitly takes deformations into
consideration~\cite{TD,HTrevor,ATV}
has a narrow focus on individual local tangent spaces, neglecting the
relations between them. As we will show, there are
significant dependencies between the different tangent spaces of the
deformation manifolds, which, if appropriately exploited,
contribute greatly to learning a model of deformation.

In this paper, we propose a new approach to deformation modeling,
where each observed image is considered to be generated by deforming
an object template. The observation of typical deformation patterns
exhibited in general images leads to the belief that most deformations
are well modeled by a low-dimensional Lie group, which can be characterized by
a basis of the associated Lie algebra. Intuitively, the Lie algebraic
basis captures the basic deformation patterns, and each deformation
in the group is some combination of them.
%
Generally, a different Lie algebra is associated with differing object
templates, which, however, are related to each other via the parallel
transport property. Specifically, the Lie algebra for one object
template is a transported version of the one for
others. The fact that parallel transport is covariant with geometric
transformation ensures the consistency of this relation.

Consequently, with the Lie algebraic characterization, the problem of learning
deformations reduce to the one of estimating the deformation basis
for different object templates. Here, we formulate an optimization problem
for estimating these bases from a given set of observed images. In
this formulation, two levels of relations are exploited:
(1) Observed images are closed to the deformation orbits, \ie~the
manifold is comprised of all deformed versions of the templates. 
(2) The basis associated with different templates are constrained by
the parallel transport relations.
The use of the first relation, which explicitly incorporates
deformation into the generative process of an image, clearly sets this
work apart from the large amount of prior work (\eg~those on image
manifold learning) that directly model the image space. Additionally,
the use of the parallel transport relation further distinguishes the
proposed approach from the methods which focus on local
neighborhoods only.

The remainder of this paper is organized as follows.
Section~\ref{sec:theory} reviews existing theoretrical results on deformations. The
emphasis is particularly placed on the Lie algebraic characterization
and parallel transport.
Section~\ref{sec:algorithm} formulates the optimization algorithm
for estimating the deformation model from observed images.
Emprirical results are presented in section~\ref{sec:experiments}, where we
compare the proposed method with related methods on character
recogition and synthesis, as well as face reconstruction.
Discussion of the method and results is provided in section~\ref{sec:conclusion}. 
%%% Local Variables:
%%% TeX-master: "main_paper"
%%% End:

